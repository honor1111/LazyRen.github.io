---
layout: post
title: "cs231n lecture#9 review"
subtitle: "cs231n lecture#9 review"
category: studies
tags: Lecture-Review
# image:
---

# Lec. 9 | CNN Architectures

Today lecture is about CNN Architectures.
![CNN-Archis](/assets/img/posts/studies/lecture-review/lec9/md-img-paste-2020-11-25-20-01-05.png)


## AlexNet

Let's start with AlexNet ( *with quiz* )

![](/assets/img/posts/studies/lecture-review/lec9/md-img-paste-2020-11-25-21-04-27.png)

Q1. 
![AlexNet-Q1](/assets/img/posts/studies/lecture-review/lec9/md-img-paste-2020-11-25-21-06-22.png)

Answer is, __55 x 55 x 96__ (W_out x H_out x Num-of-filters)

Q2.
![AlexNet-Q2](/assets/img/posts/studies/lecture-review/lec9/md-img-paste-2020-11-25-21-07-53.png)

Answer is, __(11x11x3)x96__ (W-filter x H-filter x input-depth)xNum-of-filters

Q3.
![AlexNet-Q3](/assets/img/posts/studies/lecture-review/lec9/md-img-paste-2020-11-25-21-12-05.png)

Answer is, __27x27x96__ (W_out x H_out x Num-of-depth)

Q4.
![AlexNet-Q4](/assets/img/posts/studies/lecture-review/lec9/md-img-paste-2020-11-25-21-15-06.png)

Answer is, 0 !! (Because it's *__pooling layer__*, nothing to learn. )

<br>

*Historical Note*  
At 2012, traine was done at GTX580(*quite old GPU*), which only have 3GB memory.
so divide neuron into half, and learned at each GPU.
![AlexNet-HistNote](/assets/img/posts/studies/lecture-review/lec9/md-img-paste-2020-11-25-21-57-34.png)

<br>

*Achievement*  
AlexNet is 1st winner of CNN-based network at 2012.

![AlexNet-ILSVRC](/assets/img/posts/studies/lecture-review/lec9/md-img-paste-2020-11-25-22-02-42.png)

<br>

## GoogleNet and VGGNet

Deeper! Better! ( than AlexNet )

![](/assets/img/posts/studies/lecture-review/lec9/md-img-paste-2020-11-25-22-07-59.png)

<br>

### VGGNet

Smaller filters, Deeper networks.

![VGGNet](/assets/img/posts/studies/lecture-review/lec9/md-img-paste-2020-11-25-22-09-11.png)

Q1.
![VGG-Q1](/assets/img/posts/studies/lecture-review/lec9/md-img-paste-2020-11-25-22-11-58.png)

A1.  
With smaller filter, we could have deeper network.
__three (3x3) conv (stride 1)__ layers has same effective receptive field as __one (7x7) conv layer__.

Q1-1.
![VGG-Q1-1](/assets/img/posts/studies/lecture-review/lec9/md-img-paste-2020-11-25-22-21-49.png)

A1-1.  
Answer is [7x7].  
At every coners of [3x3] looks another [3x3], so, becomes 3->5->7.
![](/assets/img/posts/studies/lecture-review/lec9/md-img-paste-2020-11-25-22-21-36.png)

So, by using smaller filter, we can get *deeper* and more *non-linearities*.  
And, fewer params : 3*(3^2C^2) vs. 7^2C^2  
(*C : input depth, total number of output feature map*) 

So the result would be like below:
![](/assets/img/posts/studies/lecture-review/lec9/md-img-paste-2020-11-25-23-57-18.png)


*Q. For each layer, what do different filters need?*  
*A. Each layer means, one feature map, one activation map of all the responses of different spatial location. Each filter correspond to a different pattern that we looking for in the input.*

*Q. Intuition for deeper network, more channel depth, more number of filters ?*  
*A. Deeper network is not mandatory. One reason is, relatively constant level of compute. Another reason is, when you go deeper, usually you'll use down sampling, which is less expensive to make deeper network.*  

*Q. I don't think we should memorize all of the data, we could throw away some parts.*  
*A. Yes, some are we don't need to keep. But we also need to save for further backprop.. So the large part of them need to save.*   